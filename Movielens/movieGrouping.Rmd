---
title: "R Notebook"
output: html_notebook
---

use top 10 from validation as a test
```{r}
library(dplyr)
mymovie <- validation %>% 
  group_by(movieId,title) %>%
  filter(n() >= 50) %>% summarise(count=n()) %>% filter(count>2750)
```

use the mapping above against edx
```{r}
mytrain <- edx %>% left_join(mymovie,by='movieId') %>% filter(!is.na(title.y)) 
dim(mytrain)
```

## movie avg and user avg
```{r}
mu = mean(mytrain$rating)
movieAvg <- mytrain %>% group_by(movieId) %>% summarise(b_m = mean(rating-mu))
userAvg <- mytrain %>% left_join(movieAvg,by='movieId') %>% group_by(userId) %>% summarise(b_u = mean(rating-b_m-mu))
```


#prediction


# steps...

# 1. find residual using below code
# 2. map it to p and q see below... 
# need to expand this table below to encompass more movies.

```{r}
pred <- mytrain %>% left_join(movieAvg,by='movieId') %>% left_join(userAvg,by='userId') %>% mutate(mu=mu,prediction=mu+b_u+b_m, residual=rating-prediction) %>% select(userId, movieId,title = title.x, mu, b_m,b_u,prediction,rating,residual,count) 
dim(pred)
head(pred)
```

```{r}
#pred %>% arrange(user,movie)
pred %>% filter(title.y=='Pulp Fiction (1994)') %>% .$residual %>% hist()
```

Working out lambda on histogram above for pulf fiction (comedy|crime|drama) to minimise the variance
```{r}
dim(pred)
lambda <- pred %>% filter(residual> 0.5 | residual < -0.5) 
dim(lambda)
```

```{r}
head(lambda)
```

#clustering lambda by users
```{r}

c_user <- lambda %>% select(userId,movieId,rating) %>% spread(movieId,rating)
rownames(c_user) <- c_user[,1] 
c_user <- c_user[,-1]
c_user[is.na(c_user)] <- 0

k <- kmeans(c_user, centers = 10, nstart=1)
groups <- k$cluster
myuser <- split(names(groups), groups)

# convert to dataframe
p <- ldply (myuser, data.frame)
colnames(p) <- c('p','userId')
p$userId <- as.numeric(as.character(p$userId))
head(p)
```


# clustering lambda by movies
```{r}
#library(plyr)
c_movie <- t(c_user)

k <- kmeans(c_movie, centers = 5, nstart=1)
groups <- k$cluster
mylist <- split(names(groups), groups)

# convert to dataframe
q <- ldply (mylist, data.frame)
colnames(q) <- c('q','movieId')
q$movieId <- as.numeric(as.character(q$movieId))

```


# create pq map.... 
# q = movie and there are 3 groupings
# p = users and there are 10 groupings
# below code should look after positive and negative
```{r}
pq_map <- lambda %>% select(userId,movieId,title.y,rating,residual) %>% left_join(q,by='movieId') %>% left_join(p,by='userId')%>%group_by(q,p) %>% summarise(lamda=mean(residual)) %>% arrange(lamda)
```


# use the code below to get verify p q calculation and to make sense of it. Amend it as required. !!
```{r}
lambda %>% select(userId,movieId,title.y,rating,residual) %>% left_join(q,by='movieId') %>% left_join(p,by='userId')%>%filter(q==4&p==1)%>% head(40)

```




# applying mapping to prediction table
```{r}
pred_final <- pred %>% left_join(movieAvg,by='movieId') %>% left_join(userAvg,by='userId') %>% left_join(q,by='movieId') %>% left_join(p,by='userId') %>% left_join(pq_map, by=c('q','p')) %>% select(userId,movieId,title,rating,prediction,residual,lamda,q,p)
pred_final$lamda[is.na(pred_final$lamda)] <- 0
pred_final <- pred_final %>% mutate(final_rating = round(prediction + lamda,3), final_res=final_rating-rating)
head(pred_final)
```

```{r}
#pred %>% arrange(user,movie)
pred_final %>% filter(title=='Forrest Gump (1994)') %>% .$residual %>% hist()
pred_final %>% filter(title=='Forrest Gump (1994)') %>% .$final_res %>% hist()
```

### this is the final sample... keep working on this... to understand how well your lamda works.!!!
```{r}
lambda %>% select(userId,movieId,title.y,rating,residual) %>% left_join(q,by='movieId') %>% left_join(p,by='userId')%>%group_by(q,p) %>% filter(q==4&p==1) %>% summarise(lamda=mean(residual)) %>% arrange(lamda)


pred_final %>% filter(q==4&p==1) %>% mutate(finalrating=round(prediction+lamda,2)) %>% select(rating,prediction,finalrating)
```












